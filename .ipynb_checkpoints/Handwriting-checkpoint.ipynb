{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:00:24.801874Z",
     "start_time": "2019-05-19T21:00:23.135281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Activation, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check If GPU Is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:00:25.188455Z",
     "start_time": "2019-05-19T21:00:25.096309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:00:26.668342Z",
     "start_time": "2019-05-19T21:00:26.662880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 574853056869783112\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13425135775581487452\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12835402464149193593\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7510949888\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13157621784009106544\n",
      "physical_device_desc: \"device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data From Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:00:29.244868Z",
     "start_time": "2019-05-19T21:00:28.953903Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_Train, Y_Train), (X_Test, Y_Test) = keras.datasets.mnist.load_data()\n",
    "X_Train = X_Train.reshape(60000,28,28,1)\n",
    "X_Test = X_Test.reshape(10000,28,28,1)\n",
    "Y_Train = to_categorical(Y_Train)\n",
    "Y_Test = to_categorical(Y_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:14:03.660632Z",
     "start_time": "2019-05-19T21:14:03.214857Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 27, 27, 64)        320       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 11, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 16)          8208      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 28,090\n",
      "Trainable params: 27,866\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model = Sequential()\n",
    "Model.add(Conv2D(64, kernel_size=2, input_shape=(28,28,1), kernel_initializer = \"uniform\"))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Model.add(Dropout(0.4))\n",
    "Model.add(Conv2D(32, kernel_size=3,  kernel_initializer= \"uniform\"))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Model.add(Dropout(0.4))\n",
    "Model.add(Conv2D(16, kernel_size=4, kernel_initializer= \"uniform\"))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(BatchNormalization())\n",
    "#Model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Model.add(Dropout(0.4))\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(10, activation=\"softmax\"))\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:00:33.959556Z",
     "start_time": "2019-05-19T21:00:33.672504Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-271e78713429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HandwritingDigitsRecognition.gv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Handwriting Digits Recognition\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/ann_visualizer/visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[0;34m(model, view, filename, title)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cluster_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Dense\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ann_viz(Model, view= True, filename=\"HandwritingDigitsRecognition.gv\", title=\"Handwriting Digits Recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile & Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T21:25:46.252719Z",
     "start_time": "2019-05-19T21:14:07.102305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.3894 - acc: 0.8807 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1669 - acc: 0.9487 - val_loss: 0.0594 - val_acc: 0.9806\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1411 - acc: 0.9563 - val_loss: 0.0517 - val_acc: 0.9828\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1291 - acc: 0.9593 - val_loss: 0.0454 - val_acc: 0.9852\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1210 - acc: 0.9623 - val_loss: 0.0408 - val_acc: 0.9864\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1133 - acc: 0.9647 - val_loss: 0.0381 - val_acc: 0.9873\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1065 - acc: 0.9673 - val_loss: 0.0377 - val_acc: 0.9869\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1035 - acc: 0.9672 - val_loss: 0.0330 - val_acc: 0.9895\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1002 - acc: 0.9688 - val_loss: 0.0357 - val_acc: 0.9888\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0964 - acc: 0.9705 - val_loss: 0.0340 - val_acc: 0.9889\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0985 - acc: 0.9695 - val_loss: 0.0358 - val_acc: 0.9882\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0936 - acc: 0.9702 - val_loss: 0.0315 - val_acc: 0.9901\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0912 - acc: 0.9711 - val_loss: 0.0310 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0912 - acc: 0.9716 - val_loss: 0.0305 - val_acc: 0.9906\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0922 - acc: 0.9718 - val_loss: 0.0330 - val_acc: 0.9889\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0874 - acc: 0.9730 - val_loss: 0.0292 - val_acc: 0.9902\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0864 - acc: 0.9729 - val_loss: 0.0284 - val_acc: 0.9903\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0878 - acc: 0.9724 - val_loss: 0.0322 - val_acc: 0.9887\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0868 - acc: 0.9728 - val_loss: 0.0286 - val_acc: 0.9911\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0842 - acc: 0.9733 - val_loss: 0.0271 - val_acc: 0.9911\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0827 - acc: 0.9741 - val_loss: 0.0312 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0816 - acc: 0.9750 - val_loss: 0.0288 - val_acc: 0.9908\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0798 - acc: 0.9753 - val_loss: 0.0274 - val_acc: 0.9906\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0814 - acc: 0.9748 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0802 - acc: 0.9749 - val_loss: 0.0309 - val_acc: 0.9904\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0824 - acc: 0.9745 - val_loss: 0.0279 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0794 - acc: 0.9747 - val_loss: 0.0291 - val_acc: 0.9902\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0787 - acc: 0.9759 - val_loss: 0.0273 - val_acc: 0.9906\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0795 - acc: 0.9753 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0771 - acc: 0.9758 - val_loss: 0.0259 - val_acc: 0.9918\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0785 - acc: 0.9756 - val_loss: 0.0250 - val_acc: 0.9924\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0761 - acc: 0.9761 - val_loss: 0.0270 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0768 - acc: 0.9761 - val_loss: 0.0274 - val_acc: 0.9910\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0765 - acc: 0.9764 - val_loss: 0.0293 - val_acc: 0.9899\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0725 - acc: 0.9775 - val_loss: 0.0264 - val_acc: 0.9915\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0731 - acc: 0.9769 - val_loss: 0.0272 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0746 - acc: 0.9768 - val_loss: 0.0251 - val_acc: 0.9925\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0739 - acc: 0.9771 - val_loss: 0.0256 - val_acc: 0.9919\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0744 - acc: 0.9766 - val_loss: 0.0247 - val_acc: 0.9922\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0739 - acc: 0.9769 - val_loss: 0.0274 - val_acc: 0.9914\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0739 - acc: 0.9767 - val_loss: 0.0271 - val_acc: 0.9907\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0730 - acc: 0.9776 - val_loss: 0.0261 - val_acc: 0.9919\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0750 - acc: 0.9764 - val_loss: 0.0251 - val_acc: 0.9921\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0721 - acc: 0.9772 - val_loss: 0.0259 - val_acc: 0.9917\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0722 - acc: 0.9771 - val_loss: 0.0263 - val_acc: 0.9910\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0749 - acc: 0.9771 - val_loss: 0.0256 - val_acc: 0.9923\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0725 - acc: 0.9769 - val_loss: 0.0260 - val_acc: 0.9910\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0753 - acc: 0.9761 - val_loss: 0.0258 - val_acc: 0.9914\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0702 - acc: 0.9781 - val_loss: 0.0257 - val_acc: 0.9919\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0698 - acc: 0.9782 - val_loss: 0.0247 - val_acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0164e75a58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "Model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test A Predictions From The Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T22:22:18.431511Z",
     "start_time": "2019-05-19T22:22:18.326906Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was The AI Right? True\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d34c1ad4128b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Was The AI Right?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA5FJREFUeJzt1MENwCAQwLDS/Xc+tgCJ2BPklTUzHwDv+28HAHCG4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QMQGL4sE9RSocXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"Was The AI Right?\", np.argmax(Y_Test[[i]]) == np.argmax(Model.predict(X_Test[[i]])))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cv2.cvtColor(X_Test[i], cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "Model.predict(X_Test[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test All Predictions From The Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T22:22:22.742504Z",
     "start_time": "2019-05-19T22:22:22.016540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy -  0.9919\n"
     ]
    }
   ],
   "source": [
    "TestPredictions = Model.predict(X_Test)\n",
    "\n",
    "ResultList = []\n",
    "for i, j in enumerate(TestPredictions):\n",
    "    ResultList.append(np.argmax(TestPredictions[i])==np.argmax(Y_Test[i]))\n",
    "print(\"Testing Set Accuracy - \", np.mean(ResultList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test A Drawing I've Made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T22:25:11.410751Z",
     "start_time": "2019-05-19T22:25:10.979515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was The AI Right? True\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d4e622494846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Was The AI Right?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA5FJREFUeJzt1MENwCAQwLDS/Xc+tgCJ2BPklTUzHwDv+28HAHCG4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QMQGL4sE9RSocXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=5\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "file_path = str((base_path / \"../Handwriting/My Images/\").resolve())\n",
    "temp = str(file_path)+\"/\"+str(i)+\".png\"\n",
    "\n",
    "img = cv2.imread(temp,0)\n",
    "img2 = cv2.bitwise_not(img)\n",
    "img3 = img2.reshape(1,28,28,1)\n",
    "\n",
    "print(\"Was The AI Right?\", i == np.argmax(Model.predict(img3)))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "Model.predict(img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test All The Drawings I've Made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"__file__\").parent\n",
    "file_path = str((base_path / \"../CNN/My Images/\").resolve())\n",
    "temp = str(file_path)+\"\\\\?.png\"\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T22:25:35.397473Z",
     "start_time": "2019-05-19T22:25:35.383470Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e1b14dc1617d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_ImageList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY_ImageList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_ImageList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY_ImageList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "X_ImageList = []\n",
    "Y_ImageList = []\n",
    "for name in glob.glob(temp):\n",
    "    X_ImageList.append(cv2.imread(name,0))\n",
    "    Y_ImageList.append(name[name.find(\".png\")-1])\n",
    "X_ImageList = np.array(X_ImageList)\n",
    "\n",
    "TestPredictions = []\n",
    "for image in X_ImageList:\n",
    "    image = cv2.bitwise_not(image)\n",
    "    image = image.reshape(1,28,28,1)\n",
    "    TestPredictions.append(Model.predict(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T22:25:37.533545Z",
     "start_time": "2019-05-19T22:25:37.521471Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-36185b776249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mResultList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestPredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mResultList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestPredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_ImageList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"My Handwriting Accuracy - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResultList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect Numbers - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_ImageList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResultList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ResultList = []\n",
    "for i, j in enumerate(TestPredictions):\n",
    "    ResultList.append(np.argmax(TestPredictions[i])==int(Y_ImageList[i]))\n",
    "print(\"My Handwriting Accuracy - \", np.mean(ResultList))\n",
    "print(\"Incorrect Numbers - \", np.array(Y_ImageList)[np.argwhere(np.array(ResultList)==False).ravel()].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amazonei_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-amazonei_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
